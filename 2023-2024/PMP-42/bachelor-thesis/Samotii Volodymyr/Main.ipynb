{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from tensorflow.python.keras.layers.pooling import GlobalAveragePooling2D \n",
    "\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_labels_emotions_sentiments(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    file_paths =  [\"./train_set/dia{}_utt{}.wav\".format(row['Dialogue_ID'], row['Utterance_ID']) for index, row in df.iterrows()]\n",
    "    labels = df['Emotion'].tolist()\n",
    "    sentiments = df['Sentiment'].tolist()\n",
    "    speakers = df['Speaker'].tolist()\n",
    "    return file_paths, labels, sentiments\n",
    "\n",
    "def extract_labels_emotions_sentiments_dev(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    file_paths =  [\"./dev_set/dia{}_utt{}.wav\".format(row['Dialogue_ID'], row['Utterance_ID']) for index, row in df.iterrows()]\n",
    "    labels = df['Emotion'].tolist()\n",
    "    sentiments = df['Sentiment'].tolist()\n",
    "    speakers = df['Speaker'].tolist()\n",
    "    return file_paths, labels, sentiments\n",
    "\n",
    "def extract_labels_emotions_sentiments_test(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    file_paths =  [\"./test_set/dia{}_utt{}.wav\".format(row['Dialogue_ID'], row['Utterance_ID']) for index, row in df.iterrows()]\n",
    "    labels = df['Emotion'].tolist()\n",
    "    sentiments = df['Sentiment'].tolist()\n",
    "    return file_paths, labels, sentiments\n",
    "\n",
    "train_file_path = './filtered_file.csv'\n",
    "test_file_path = './test_sent_emo.csv'\n",
    "dev_file_path = './dev_sent_emo.csv'\n",
    "\n",
    "train_file_paths, train_labels, train_sentiments = extract_labels_emotions_sentiments(train_file_path)\n",
    "test_file_paths, test_labels, test_sentiments = extract_labels_emotions_sentiments_test(test_file_path)\n",
    "dev_file_paths, dev_labels, dev_sentiments = extract_labels_emotions_sentiments_dev(dev_file_path)\n"
   ],
   "id": "ebee056daf0b9c4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_wave_mel(audio_path):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title('Waveplot')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.show()\n",
    "\n",
    "print(train_file_path[0])\n",
    "\n",
    "plot_wave_mel(train_file_paths[0])"
   ],
   "id": "7993cacc42915b76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# NOISE\n",
    "def add_noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "# STRETCH\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "# SHIFT\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "# PITCH\n",
    "def pitch_shift(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
   ],
   "id": "7d0c65ffaa553de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def extract_features(audio_path, sr=22050, n_mfcc=13, n_mels=128, n_components=30, fixed_length=200):\n",
    "    \n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    \n",
    "    msf = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    msf_db = librosa.power_to_db(msf, ref=np.max)\n",
    "    \n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
    "    pitch = pitches[np.nonzero(pitches)]\n",
    "    pitch_mean = np.mean(pitch) if len(pitch) > 0 else 0\n",
    "    \n",
    "    energy = np.sum(librosa.feature.rms(y=y))\n",
    "    \n",
    "    combined_features = np.vstack((mfccs, msf_db))\n",
    "    \n",
    "    pitch_energy_features = np.array([[pitch_mean, energy]])\n",
    "    pitch_energy_features = np.tile(pitch_energy_features, (combined_features.shape[1], 1)).T\n",
    "    combined_features = np.vstack((combined_features, pitch_energy_features))\n",
    "\n",
    "    if combined_features.shape[1] < fixed_length:\n",
    "        padding = np.zeros((combined_features.shape[0], fixed_length - combined_features.shape[1]))\n",
    "        combined_features = np.hstack((combined_features, padding))\n",
    "    elif combined_features.shape[1] > fixed_length:\n",
    "        combined_features = combined_features[:, :fixed_length]\n",
    "    \n",
    "    combined_features_flattened = combined_features.reshape(combined_features.shape[0], -1).T\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_features = pca.fit_transform(combined_features_flattened)\n",
    "    \n",
    "    reduced_features = reduced_features.T\n",
    "    reduced_features = np.expand_dims(reduced_features, axis=-1)\n",
    "    \n",
    "    return reduced_features\n",
    "\n",
    "audio_file = './train_set/dia445_utt3.wav'\n",
    "\n",
    "feat = extract_features(audio_file)\n",
    "feat\n",
    "\n"
   ],
   "id": "f7e6d18b0c4ffe4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feat = extract_features(audio_file)\n",
    "feat\n",
    "\n",
    "df_list = [pd.DataFrame(sub_array) for sub_array in feat]\n",
    "\n",
    "df_list"
   ],
   "id": "f83d83c628e1e4bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unfound_files_train = []\n",
    "unfound_files_test = []\n",
    "unfound_files_dev = []\n",
    "\n",
    "featurs_dir = './featuers/'\n",
    "def extract_and_save_features(file_paths):\n",
    "    features = []\n",
    "    for file_path in file_paths:\n",
    "        feature = extract_features(file_path)\n",
    "        features.append(feature)\n",
    "    return features\n",
    "audio_base_path = './train_set/'\n",
    "feature_base_path_train = './filtered_file.csv'\n",
    "feature_base_path_test = './test_sent_emo.csv'\n",
    "feature_base_path_dev = './dev_sent_emo.csv'\n",
    "\n",
    "\n"
   ],
   "id": "26fa0e3f0cfc4f64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "X_dev = extract_and_save_features(dev_file_paths, feature_base_path_dev)\n",
    "\n",
    "X_dev"
   ],
   "id": "16631d919a73cced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_msf_with_waveplot(audio_path, sr=22050, n_mels=128):\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    \n",
    "    msf = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    msf_db = librosa.power_to_db(msf, ref=np.max)\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "\n",
    "    ax2 = fig.add_subplot(2, 1, 2, projection='3d')\n",
    "    time = np.linspace(0, len(y) / sr, msf.shape[1])\n",
    "    mel_frequencies = librosa.mel_frequencies(n_mels=n_mels, fmin=0, fmax=sr/2)\n",
    "    time, mel_frequencies = np.meshgrid(time, mel_frequencies)\n",
    "    \n",
    "    ax2.plot_surface(time, mel_frequencies, msf_db, cmap='viridis')\n",
    "    ax2.set_title('MSF')\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Mel Frequency')\n",
    "    ax2.set_zlabel('Amplitude (dB)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "audio_file = './dia445_utt3.wav'\n",
    "plot_msf_with_waveplot(audio_file)"
   ],
   "id": "61b8bb2ec8285f7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x_dev_nparray = np.array(X_dev)",
   "id": "ca26b88a141ff1d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train = extract_and_save_features(train_file_paths, feature_base_path_train)\n",
   "id": "ca32189a794a983c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_test = extract_and_save_features( test_file_paths, feature_base_path_test)",
   "id": "7a54e92b52350564",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(type(X_train), type(X_test), type(x_dev_nparray))",
   "id": "93995dcf80ba321c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_train_nparray = np.array(X_train)\n",
    "x_test_nparray = np.array(X_test)\n",
    "print(type(x_train_nparray), type(x_test_nparray), type(x_dev_nparray))\n",
    "print(x_train_nparray.shape, x_test_nparray.shape, x_dev_nparray.shape)"
   ],
   "id": "f164b7b6deebf793",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "print(f\"Train X: {len(X_train)}, y: {len(train_labels)}\")\n",
    "print(f\"Test X: {len(X_test)}, y: {len(test_labels)}\")\n",
    "print(f\"Dev X: {len(X_dev)}, y: {len(dev_labels)}\")\n",
    "\n",
    "print(f\"Train X: {len(X_train)}, y: {len(train_labels)}\")\n",
    "print(f\"Test X: {len(X_test)}, y: {len(test_labels)}\")\n",
    "print(f\"Dev X: {len(X_dev)}, y: {len(dev_labels)}\")"
   ],
   "id": "ba3ac4e30d7ec35f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "print(f\"Train X: {len(X_train)}, y: {len(train_labels)}\")\n",
    "print(f\"Test X: {len(X_test)}, y: {len(test_labels)}\")\n",
    "print(f\"Dev X: {len(X_dev)}, y: {len(dev_labels)}\")\n",
    "\n",
    "print(f\"Train X: {len(X_train)}, y: {len(train_labels)}\")\n",
    "print(f\"Test X: {len(X_test)}, y: {len(test_labels)}\")\n",
    "print(f\"Dev X: {len(X_dev)}, y: {len(dev_labels)}\")\n",
    "\n",
    "train_arr = np.array(X_train)\n",
    "test_arr = np.array(X_test)\n",
    "dev_arr = np.array(X_dev)\n",
    "\n",
    "X_train_model = np.expand_dims(x_train_nparray, axis=-2)\n",
    "X_test_model = np.expand_dims(x_test_nparray, axis=-2)\n",
    "X_dev_model = np.expand_dims(x_dev_nparray, axis=-2)\n"
   ],
   "id": "569c34684acb9530",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_train_nparray.shape\n",
    "len(X_train_model.shape)\n",
    "X_train_model.shape\n",
    "target_shape = (-1, 30, 200, 1)\n",
    "X_train_model_res = X_train_model.reshape(target_shape)\n",
    "X_train_model_res.shape"
   ],
   "id": "9555d542ebdeec99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def get_label_from_file_path(file_path):\n",
    "    filename = os.path.basename(file_path)\n",
    "    label = filename.split('_')[0] \n",
    "    return label\n",
    "\n",
    "def load_data(data_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            data = extract_features(file_path)\n",
    "            if data is not None:\n",
    "                features.append(data)\n",
    "                labels.append(get_label_from_file_path(file_path))\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "data_dir = './train_set/'\n",
    "X_train, y_train = load_data(data_dir)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)"
   ],
   "id": "aabbb082198a744a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "le_labels = LabelEncoder()\n",
    "y_train_encoded = le_labels.fit_transform(train_labels)\n",
    "y_test_encoded = le_labels.transform(test_labels)\n",
    "y_dev_encoded = le_labels.transform(dev_labels)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y_train_categorical = encoder.fit_transform(np.array(y_train_encoded).reshape(-1,1)).toarray()\n",
    "y_test_categorical = encoder.fit_transform(np.array(y_test_encoded).reshape(-1,1)).toarray()\n",
    "y_dev_categorical = encoder.fit_transform(np.array(y_dev_encoded).reshape(-1,1)).toarray()\n"
   ],
   "id": "7e07ec2488c1013c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "labels_one_hot = encoder.fit_transform(y_train_encoded.reshape(-1, 1))\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "labels_one_hot_test = encoder.fit_transform(y_test_encoded.reshape(-1, 1))\n",
    "\n",
    "print(\"Розмірність лейблів після кодування:\", labels_one_hot.shape)"
   ],
   "id": "df009d4d551caaf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (5, 5), activation='relu', input_shape=(200, 216, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 1), strides=(2, 1), padding='valid'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (1, 1), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(1, 1), strides=(1, 1), padding='valid'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "initial_lr = 0.001\n",
    "optimiser = Adam(learning_rate=initial_lr)\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "id": "4d716dfb15357961",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "history = model.fit(X_train_model_res, labels_one_hot, \n",
    "                    epochs=50, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(X_test_model, labels_one_hot_test), \n",
    "                    callbacks=[reduce_lr])\n"
   ],
   "id": "fee5dd9ff7e94f69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_history(history):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n"
   ],
   "id": "85a70129b0148973",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_file_path = './dia4_utt6.wav'\n",
    "sample2_file_path = './Recording2.wav'\n",
    "\n",
    "sample_features = extract_features(sample2_file_path)\n",
    "reshaped_sample = sample_features.reshape(target_shape)\n",
    "prediction = model.predict(reshaped_sample)\n",
    "predicted_label = le_labels.inverse_transform([np.argmax(prediction)])\n",
    "print(f\"Predicted Emotion: {predicted_label[0]}\")"
   ],
   "id": "6f843764f495864",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "isiah_neutral = './redacted_Isiah_neutral.wav'\n",
    "isiah_anger = './redacted_Isiah.wav'\n",
    "pogliad = './pogliad.wav'\n",
    "def plot_wave_mel(audio_path):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title('Waveplot')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.show()\n",
    "\n",
    "plot_wave_mel(pogliad)"
   ],
   "id": "36cdf135b522d309",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_msf(y, sr, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    \n",
    "    log_mel_spectrogram = librosa.amplitude_to_db(mel_spectrogram)\n",
    "    \n",
    "    modulation_spectrum = np.abs(np.fft.fft(log_mel_spectrogram, axis=1))\n",
    "    \n",
    "    modulation_spectrum = modulation_spectrum[:, :modulation_spectrum.shape[1] // 2]\n",
    "    \n",
    "    return modulation_spectrum\n",
    "\n",
    "y, sr = librosa.load(pogliad)\n",
    "\n",
    "msf = compute_msf(y, sr)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "X, Y = np.meshgrid(np.arange(msf.shape[1]), np.arange(msf.shape[0]))\n",
    "\n",
    "ax.plot_surface(X, Y, msf, cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('Modulation Frequency')\n",
    "ax.set_ylabel('Mel Frequency')\n",
    "ax.set_zlabel('Amplitude (dB)')\n",
    "ax.set_title('Modulation Spectral Features (MSF)')\n",
    "\n",
    "plt.show()"
   ],
   "id": "7bf933db81b6f6a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6a9cbe8a64b34334",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
